Как настроить многоузловой кластер Airflow с помощью Celery и RabbitMQ

Что такое Airflow?

Программно создавайте, планируйте и контролируйте рабочий процесс. Он предоставляет функциональную абстракцию в виде идемпотентного DAG (направленного ациклического графа). Функция как служба абстракции для выполнения задач с заданными интервалами.

 

**Кластер с одним узлом Airflow**

В одноузловом кластере Airflow все компоненты (рабочий, планировщик, веб-сервер) установлены на одном узле, известном как "**Master узел**". Чтобы масштабировать кластер с одним узлом, `Airflow` должен быть настроен в режиме `LocalExecutor`. Worker вытягивает задачу из очереди IPC (межпроцессное взаимодействие), это очень хорошо масштабируется до тех пор, пока количество ресурсов, доступных на главном узле, не будет. Чтобы масштабировать Airflow на мультиузле, необходимо включить `Celery Executor`.

![](https://habrastorage.org/webt/g_/ue/mb/g_uembs8k7irgrfhuwdl-zcjl34.png)

**Многоузловой кластер Airflow**

В многоузловой архитектуре Airflow процессы демонстрации распределены по всем рабочим узлам. Поскольку веб-сервер и планировщик будут установлены на главном узле, а рабочие будут установлены на каждом отдельном рабочем узле, поэтому он может хорошо масштабироваться как по горизонтали, так и по вертикали. Чтобы использовать этот режим архитектуры, необходимо настроить Airflow с помощью `CeleryExecutor`.

Серверную часть Celery необходимо настроить для включения режима `CeleryExecutor` в архитектуре Airflow. Популярными фреймворками / приложениями для бэкэнда Celery являются Redis и RabbitMQ. RabbitMQ - это брокер сообщений. Его задача - управлять обменом данными между несколькими службами задач путем управления очередями сообщений. Вместо канала связи IPC, который был бы в архитектуре с одним узлом, RabbitMQ предоставляет модель механизма публикации - подписчика для обмена сообщениями в разных очередях. Каждая очередь в RabbitMQ опубликована с событиями / сообщениями в виде команд задач, работники Celery будут извлекать команды задач из каждой очереди и выполнять их как действительно распределенные и параллельные способы. Что действительно может ускорить действительно мощное одновременное и параллельное выполнение задач в кластере.

![](https://habrastorage.org/webt/ww/5x/ot/ww5xot0xyqyhtzzst7h2yxftoty.png)

**Celery:**

Celery - это асинхронная очередь задач, основанная на распределенной передаче сообщений. Он ориентирован на работу в реальном времени, но также поддерживает планирование. Airflow использует его для выполнения нескольких параллельных операций на уровне задач на нескольких рабочих узлах с использованием многопроцессорности и многозадачности. Многоузловая архитектура Airflow позволяет масштабировать Airflow, легко добавляя новых сотрудников.

 

**Многоузловой кластер Airflow с шагами установки и настройки Celery:**

Примечание. Мы используем операционную систему CentOS 7 Linux.

1. Установка RabbitMQ

   ```
   yum install epel-release
   yum install rabbitmq-server
   ```

2. Включение и запуск RabbitMQ Server

   ```
   systemctl enable rabbitmq-server.service
   systemctl start rabbitmq-server.service
   ```

3. Включение интерфейса веб-консоли управления RabbitMQ

   ```
   rabbitmq-plugins enable rabbitmq_management
   ```

![](https://habrastorage.org/webt/-m/az/c9/-mazc90wejh6tbhw4i9wkx3ryry.png)

Номер порта сервера rabbitmq по умолчанию - 15672, имя пользователя и пароль по умолчанию для веб-консоли управления - `admin/admin`.

![](https://habrastorage.org/webt/vw/lt/wu/vwltwuqgmlt_gmbbqjeaqbbemng.png)

4. Установка протокола транспорта `pyamqp` для RabbitMQ и PostGreSQL Adapter

 ```
pip install pyamqp
 ```



`amqp://` - это псевдоним, который использует librabbitmq, если он доступен, или `py-amqp`, если его нет.

Вы должны использовать `pyamqp://` или `librabbitmq://`, если хотите точно указать, какой протокол передачи данных использовать. Протокол `pyamqp://` использует библиотеку `amqp` (http://github.com/celery/py-amqp)

 

**Установка адаптера PostGreSQL Adaptor: psycopg2**

Psycopg - это адаптер PostgreSQL для языка программирования Python.

```
pip install psycopg2
```

5. Установка Airflow.

```
pip install 'apache-airflow[all]'
```

Проверьте версию airflow

```
airflow version
```

![](https://habrastorage.org/webt/ni/-p/z_/ni-pz_nqcodhqqkh4brouiq7p64.png)

Мы используем версию Airflow v1.10.0, рекомендованную и стабильную в настоящее время.

6. Инициализация базы данных

```
airflow initdb
```

После установки и настройки вам необходимо инициализировать базу данных, прежде чем вы сможете запустить группы обеспечения доступности баз данных и ее задачу. Поэтому последние изменения будут отражены в метаданных Airflow из конфигурации.

 

7. Установка Celery

Celery должен быть установлен на главном узле и на всех рабочих узлах.

```
pip install celery==4.3.0
```

Проверка версии Celery

```
celery --version
4.3.0 (rhubarb)
```

8. Изменение файла airflow.cfg для Celery Executor.

```
executor = CeleryExecutor
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@{HOSTNAME}/airflow 
broker_url= pyamqp://guest:guest@{RabbitMQ-HOSTNAME}:5672/
celery_result_backend = db+postgresql://airflow:airflow@{HOSTNAME}/airflow 
dags_are_paused_at_creation = True
load_examples = False
```

После внесения этих изменений в файл конфигурации `airflow.cfg` необходимо обновить метаданные airflow с помощью команды `airflow initdb`, а затем перезапустить `airflow`.

Теперь вы можете запустить веб-сервер airflow с помощью следующей команды

```
# default port is 8080
airflow webserver -p 8000
```

Вы можете запустить планировщик

```
# start the scheduler
airflow scheduler
```

Вы также должны запустить airflow на каждом рабочем узле.

```
airflow worker
```

Как только вы закончите запускать различные службы airflow, вы можете проверить фантастический интерфейс airflow при помощи команды:

```
http://<IP-ADDRESS/HOSTNAME>:8000
```

поскольку мы указали порт 8000 в нашей команде запуска службы веб-сервера, в противном случае номер порта по умолчанию - 8080.

Да! Мы закончили создание кластера с многоузловой архитектурой Airflow. :)
