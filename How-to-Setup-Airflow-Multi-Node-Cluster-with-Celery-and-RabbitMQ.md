Как настроить многоузловой кластер Airflow с помощью Celery и RabbitMQ
Что такое Airflow?
Программно создавайте, планируйте и контролируйте рабочий процесс. Он предоставляет функциональную абстракцию в виде идемпотентного DAG (направленного ациклического графа). Функция как служба абстракции для выполнения задач с заданными интервалами.

Кластер с одним узлом Airflow
В одноузловом кластере Airflow все компоненты (рабочий, планировщик, веб-сервер) установлены на одном узле, известном как «Главный узел». Чтобы масштабировать кластер с одним узлом, Airflow должен быть настроен в режиме LocalExecutor. Worker вытягивает задачу из очереди IPC (межпроцессное взаимодействие), это очень хорошо масштабируется до тех пор, пока количество ресурсов, доступных на главном узле, не будет. Чтобы масштабировать Airflow на мультиузле, необходимо включить Celery Executor.

Многоузловой кластер Airflow
В многоузловой архитектуре Airflow процессы демонстрации распределены по всем рабочим узлам. Поскольку веб-сервер и планировщик будут установлены на главном узле, а рабочие будут установлены на каждом отдельном рабочем узле, поэтому он может хорошо масштабироваться как по горизонтали, так и по вертикали. Чтобы использовать этот режим архитектуры, необходимо настроить Airflow с помощью CeleryExecutor.
Серверную часть Celery необходимо настроить для включения режима CeleryExecutor в архитектуре Airflow. Популярными фреймворками / приложениями для бэкэнда Celery являются Redis и RabbitMQ. RabbitMQ - это брокер сообщений. Его задача - управлять обменом данными между несколькими службами задач путем управления очередями сообщений. Вместо канала связи IPC, который был бы в архитектуре с одним узлом, RabbitMQ предоставляет модель механизма публикации - подписчика для обмена сообщениями в разных очередях. Каждая очередь в RabbitMQ опубликована с событиями / сообщениями в виде команд задач, работники Celery будут извлекать команды задач из каждой очереди и выполнять их как действительно распределенные и параллельные способы. Что действительно может ускорить действительно мощное одновременное и параллельное выполнение задач в кластере.

Celery:
Celery - это асинхронная очередь задач, основанная на распределенной передаче сообщений. Он ориентирован на работу в реальном времени, но также поддерживает планирование. Airflow использует его для выполнения нескольких параллельных операций на уровне задач на нескольких рабочих узлах с использованием многопроцессорности и многозадачности. Многоузловая архитектура Airflow позволяет масштабировать Airflow, легко добавляя новых сотрудников.

Многоузловой кластер Airflow с шагами установки и настройки Celery:
Примечание. Мы используем операционную систему CentOS 7 Linux.
1.	Установка RabbitMQ
2.	Включение и запуск RabbitMQ Server
3.	Включение интерфейса веб-консоли управления RabbitMQ
Номер порта сервера rabbitmq по умолчанию - 15672, имя пользователя и пароль по умолчанию для веб-консоли управления - admin / admin.
4.	Установка протокола транспорта pyamqp для RabbitMQ и PostGreSQL Adapter

amqp: // - это псевдоним, который использует librabbitmq, если он доступен, или py-amqp, если его нет.
Вы должны использовать pyamqp: // или librabbitmq: //, если хотите точно указать, какой протокол передачи данных использовать. Протокол pyamqp: // использует библиотеку amqp (http://github.com/celery/py-amqp)

Установка адаптера PostGreSQL Adaptor: psycopg2
Psycopg - это адаптер PostgreSQL для языка программирования Python.
5.	Установка Airflow.
Проверьте версию airflow

Мы используем версию Airflow v1.10.0, рекомендованную и стабильную в настоящее время.
6. Инициализация базы данных
После установки и настройки вам необходимо инициализировать базу данных, прежде чем вы сможете запустить группы обеспечения доступности баз данных и ее задачу. Поэтому последние изменения будут отражены в метаданных Airflow из конфигурации.

7. Установка Celery
Celery должен быть установлен на главном узле и на всех рабочих узлах.

Проверка версии Celery
8. Изменение файла airflow.cfg для Celery Executor.

После внесения этих изменений в файл конфигурации airflow.cfg необходимо обновить метаданные airflow с помощью команды airflow initdb, а затем перезапустить airflow.

Теперь вы можете запустить веб-сервер airflow с помощью следующей команды
Вы можете запустить планировщик
Вы также должны запустить airflow на каждом рабочем узле.

Как только вы закончите запускать различные службы airflow, вы можете проверить фантастический интерфейс airflow при помощи команды:

поскольку мы указали порт 8000 в нашей команде запуска службы веб-сервера, в противном случае номер порта по умолчанию - 8080.
Да! Мы закончили создание кластера с многоузловой архитектурой Airflow. :)
