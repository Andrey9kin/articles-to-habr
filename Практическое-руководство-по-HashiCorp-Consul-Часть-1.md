Практическое руководство по HashiCorp Consul — Часть 1

![](https://habrastorage.org/webt/r-/-d/a0/r--da0gbyafieifqbiwxezr48a4.jpeg)

Это часть 1 из серии 2 частей практического руководства по HashiCorp Consul. Эта часть в первую очередь ориентирована на понимание проблем, которые решает Consul и как он их решает. Вторая часть больше ориентирована на практическое применение Consul в реальном примере и будет опубликована на следующей неделе. Давайте начнем.

Как насчет настройки обнаруживаемой, настраиваемой и безопасной сервисной сетки с помощью одного инструмента?

Что, если мы скажем вам, что этот инструмент не зависит от платформы и готов к работе в облаке?

И поставляется в виде одной двоичной загрузки.

Все это правда. Инструмент, о котором мы говорим, - это HashiCorp Consul.

Consul обеспечивает обнаружение служб, проверку работоспособности, балансировку нагрузки, график служб, принудительное использование идентификационных данных с помощью TLS и управление конфигурацией распределенных служб.

Давайте подробнее познакомимся с Consul ниже и посмотрим, как он решает эти сложные задачи и облегчает жизнь оператору распределенной системы.

### Вступление

Микросервисы и другие распределенные системы могут обеспечить более быструю и простую разработку программного обеспечения. Но есть компромисс, приводящий к большей сложности работы в области межсервисного взаимодействия, управления конфигурацией и сегментации сети.

![](https://habrastorage.org/webt/yv/ej/qz/yvejqzhsqrydqvh7ltyvej9h6fq.png)

Монолитное приложение (репрезентативное) — с различными подсистемами A, B, C и D

Распределенное приложение (репрезентативное) — с различными сервисами A, B, C и D

HashiCorp Consul – это инструмент с открытым исходным кодом, который решает эти новые сложности, предоставляя обнаружение служб, проверку работоспособности, балансировку нагрузки, график служб, взаимное применение идентификации TLS и хранилище конфигурационных ключей. Эти особенности делают Consul идеальной плоскостью управления для сервисной сетки.

HashiCorp Consul поддерживает обнаружение сервисов, конфигурацию сервисов и сегментацию сервисов.

HashiCorp объявил Consul в апреле 2014 года, и с тех пор она получила хорошее признание сообщества.

Это руководство предназначено для обсуждения некоторых из этих важнейших проблем и изучения различных решений, предлагаемых Consul HashiCorp для решения этих проблем.

Давайте кратко рассмотрим темы, которые мы собираемся охватить в этом руководстве. Темы написаны так, чтобы быть самодостаточными. Вы можете перейти непосредственно к конкретной теме, если хотите.

Краткая справка о Монолитных и Сервис-ориентированных архитектурах (SOA)

Рассматривая традиционные архитектуры доставки приложений, мы находим классический монолит. Когда мы говорим о Монолитных архитектурах, у нас есть развертывание одного приложения.

Даже если это одно приложение, обычно оно имеет несколько различных субкомпонентов.

Один из примеров, который технический директор HashiCorp Армон Дадгар привел во время своего вступительного видео для Consul, был о поставке настольного банковского приложения. Он имеет дискретный набор субкомпонентов-например, аутентификацию (скажем, подсистема а), управление счетами (подсистема в), перевод средств (подсистема С) и обмен валюты (подсистема D).

Теперь, хотя это независимые функции — аутентификация системы А против перевода средств системы С, — мы развертываем его как единое монолитное приложение.

За последние несколько лет мы наблюдаем тенденцию отхода от такого рода архитектуры. Есть несколько причин для этого сдвига.

Задача с монолитной архитетурой такова: предположим, что в одной из подсистем, системе A, есть ошибка, связанная с аутентификацией.

Репрезентативная ошибка в подсистеме А в нашем монолитном приложении

Мы не можем просто исправить его в системе А и обновить его в производстве.

Исправление репрезентативной ошибки в подсистеме А в нашем монолитном приложении

Мы должны обновить систему А и выполнить повторное развертывание всего приложения, для чего нам также необходимо развертывание подсистем В, С и D.

Исправление ошибок в одной подсистеме приводит к перераспределению всего монолитного приложения

Вся эта передислокация не идеальна. Вместо этого мы хотели бы сделать развертывание отдельных служб.

Одно и то же монолитное приложение поставляется в виде набора отдельных, дискретных сервисов.

Разделение монолитного приложения на отдельные сервисы

Итак, если есть исправление ошибки в одном из наших сервисов:

Репрезентативная ошибка в одном из сервисов, в данном случае сервисе А нашего SOA-приложения, и мы исправляем эту ошибку:

Исправление репрезентативной ошибки в сервисе A нашего SOA-приложения

Мы можем осуществить передислокацию этой службы, не согласовывая ее развертывание с другими службами. По сути, речь идет об одной из форм микросервисов.

Исправление ошибки приведет к перераспределению только службы А во всем нашем приложении

Это дает большой толчок к нашей гибкости развития. Нам не нужно координировать наши усилия по разработке между различными командами разработчиков или даже системами. У нас будет свобода развиваться и развертываться независимо. Одна услуга предоставляется еженедельно, а другая-ежеквартально. Это будет большим преимуществом для команд разработчиков.

Но такого понятия, как бесплатный обед, не существует.

Эффективность развития, которую мы получили, вводит свой собственный набор оперативных проблем. Давайте посмотрим на некоторые из них.

Обнаружение сервиса в монолитной архитектуре, его проблемы в распределенной системе и решение Consul

Монолитные приложения

Предположим, что две службы в одном приложении хотят общаться друг с другом. Один из способов-раскрыть метод - сделать его общедоступным и разрешить другим службам вызывать его. В монолитном приложении это одно приложение, в котором службы будут предоставлять общедоступные функции посредством вызова функций между службами.

Подсистемы общаются друг с другом через вызов функции в нашем монолитном приложении

Поскольку это вызов функции внутри процесса, он произошел в памяти. Это происходит быстро, поэтому нам не нужно беспокоиться о том, как были перемещены наши данные и были ли они безопасны.

Распределенная система

В распределенном мире служба A больше не поставляется как то же приложение, что и Служба B. Итак, как служба A находит службу B, если она хочет поговорить с Б?

Служба A пытается найти службу Б для установления связи

Служба A может даже не находиться на той же машине, что и Служба B. Таким образом, в игре присутствует сеть. Но это происходит не так быстро, так как есть задержка, которую мы можем измерить на линиях миллисекунд, по сравнению с наносекундами простого вызова функции.

Проблемы в распределенных системах

Как мы уже знаем, две службы в распределенной системе должны обнаружить друг друга, чтобы взаимодействовать. Одним из традиционных способов решения этой проблемы является использование балансировщиков нагрузки.

Балансировщик нагрузки находится между службами, чтобы они могли общаться друг с другом

Балансировщики нагрузки будут сидеть перед каждой службой со статическим IP-адресом, известным всем другим службам.

Балансировщик нагрузки между двумя службами позволяет осуществлять двусторонний трафик

Это дает возможность добавить несколько экземпляров одной и той же службы за балансировщиком нагрузки, и он будет направлять трафик соответствующим образом. Но этот IP-адрес балансировщика нагрузки статичен и жестко закодирован во всех других службах, поэтому службы могут пропустить обнаружение.

Балансировщики нагрузки позволяют осуществлять связь между несколькими экземплярами одной и той же службы

Теперь задача состоит в том, чтобы поддерживать набор балансировщиков нагрузки для каждой отдельной службы. И мы можем с уверенностью предположить, что изначально существовал балансировщик нагрузки и для всего приложения. Затраты и усилия на поддержание этих балансировщиков нагрузки возросли.

С балансировщиками нагрузки перед службами они представляют собой единую точку сбоев. Даже если у нас есть несколько экземпляров службы за балансировщиком нагрузки, если он не работает, наша служба не работает. Независимо от того, сколько экземпляров этой службы запущено.

Балансировщики нагрузки также увеличивают задержку межсервисного взаимодействия. Если служба A хочет поговорить со службой B, запрос от A должен сначала поговорить с балансировщиком нагрузки службы B, а затем достичь Б. Ответ от B также должен будет пройти через тот же самый маршрут

Поддержание записи экземпляров службы в балансировщике нагрузки для всего приложения

И по своей природе балансировщики нагрузки в большинстве случаев управляются вручную. Если мы добавим еще один экземпляр сервиса, он будет недоступен. Нам нужно будет зарегистрировать эту службу в балансировщике нагрузки, чтобы сделать ее доступной для всего мира. Это потребует ручных усилий и времени.

Решения Consul

Решение Consul для решения проблемы обнаружения служб в распределенных системах - это центральный реестр служб.

Consul ведет центральный реестр, содержащий записи для всех вышестоящих служб. При запуске экземпляра службы он регистрируется в центральном реестре. Реестр заполняется всеми вышестоящими экземплярами службы.

Реестр услуг Consul помогает службе A найти службу Б и установить связь

Когда служба A хочет поговорить со службой B, она обнаруживает и связывается с B, запрашивая реестр о вышестоящих экземплярах службы B. Таким образом, вместо разговора с балансировщиком нагрузки служба может напрямую связаться с желаемым конечным экземпляром службы.

Consul также обеспечивает проверку работоспособности этих экземпляров службы. Если один из экземпляров службы или сама служба не работает или не проходит проверку работоспособности, реестр будет знать об этом сценарии и будет избегать возврата адреса службы. Работа, которую будет выполнять балансировщик нагрузки, в этом случае выполняется реестром.

Кроме того, если существует несколько экземпляров одной и той же службы, Consul будет посылать трафик случайным образом в разные экземпляры. Таким образом, выравнивая нагрузку между различными экземплярами.

Consul справился с нашими задачами обнаружения сбоев и распределения нагрузки между несколькими экземплярами служб без необходимости развертывания централизованного балансировщика нагрузки.

Здесь решается традиционная проблема медленных и управляемых вручную балансировщиков нагрузки. Консул программно управляет реестром, который обновляется, когда любая новая служба регистрируется и становится доступной для приема трафика.

Это помогает с легкостью масштабировать сервисы.

Управление конфигурацией в монолите, его проблемы в распределенной среде и решение Consul

Монолитные Приложения

Когда мы смотрим на конфигурацию для монолитного приложения, они, как правило, находятся где-то на уровне гигантских файлов YAML, XML или JSON. Предполагается, что эта конфигурация настроит все приложение.

Единый конфигурационный файл, общий для различных частей нашего монолитного приложения

Учитывая один файл, все наши подсистемы в нашем монолитном приложении теперь будут потреблять конфигурацию из одного и того же файла. Таким образом, создается согласованное представление обо всех наших подсистемах или услугах.

Если мы хотим изменить состояние приложения с помощью обновления конфигурации, оно будет легко доступно для всех подсистем. Новая конфигурация одновременно потребляется всеми компонентами нашего приложения.

Распределенная система

В отличие от монолитной системы, распределенные сервисы не будут иметь общего представления о конфигурации. Конфигурация теперь распределена, и там каждая отдельная служба должна быть настроена отдельно.

Копия конфигурации приложения распределяется между различными службами

Проблемы в распределенных системах

Конфигурация должна быть распределена между различными службами. Поддержание согласованности между конфигурациями в различных службах после каждого обновления является сложной задачей.

Кроме того, проблема возрастает, когда мы ожидаем, что конфигурация будет обновляться динамически.

Решения Консула

Решение Consul для управления конфигурацией в распределенной среде - это центральное хранилище ключей и значений.

Набор Consul’s KV дает возможность плавного отображения конфигурации на каждую услугу

Консул решает эту задачу уникальным способом. Вместо того чтобы распределять конфигурацию между различными распределенными службами в виде частей конфигурации, он передает всю конфигурацию всем службам и динамически настраивает их в распределенной системе.

Возьмем пример изменения состояния в конфигурации. Измененное состояние передается через все службы в режиме реального времени. Конфигурация последовательно присутствует во всех службах.

Сегментация сети в монолите, ее проблемы в распределенных системах и решения Consul

Монолитные приложения

При рассмотрении классической монолитной архитектуры, сеть обычно делится на три различные зоны.

Первая зона в нашей сети является общедоступной. Трафик, поступает в наше приложение через интернет и достигает наших балансировщиков нагрузки.

Вторая зона - это трафик от наших балансировщиков нагрузки к нашему приложению. В основном это внутренняя сетевая зона без прямого публичного доступа.

Третья зона - это закрытая сетевая зона, предназначенная в первую очередь для передачи данных. Это считается изолированной зоной.

Различные сетевые зоны в типичном приложении

Только зона балансировщиков нагрузки может попасть в зону приложения, и только зона приложения может попасть в зону данных. Это простая система зонирования, простая в реализации и управлении.

Распределенная система

Для распределенных сервисов картина кардинально меняется.

Сложная структура сетевого трафика и маршрутов между различными сервисами

В самой зоне нашей прикладной сети существует несколько служб. Каждая из этих служб взаимодействует с другими внутри этой сети, что делает ее сложной структурой трафика.

Проблемы в распределенных системах

Основная проблема заключается в том, что трафик не находится в каком-либо последовательном потоке, в отличие от монолитной архитектуры, где поток был определен от балансировщиков нагрузки к приложению и от приложения к данным.

В зависимости от модели доступа, которую мы хотим поддерживать, трафик может поступать с разных конечных точек и достигать разных служб.

Клиент по существу общается с каждой службой в приложении прямо или косвенно

Учитывая наличие нескольких служб и возможность поддержки нескольких конечных точек, мы можем развернуть несколько потребителей и поставщиков услуг.

Из - за природы системы безопасность является нашей следующей задачей. Службы должны быть в состоянии определить, что трафик, который они получают, исходит от проверенного и доверенного объекта в сети.

SOA требует контроля над надежными и ненадежными источниками трафика

Управление потоком трафика и сегментирование сети на группы или блоки станет более серьезной проблемой. Кроме того, очень важно убедиться, что у нас есть строгие правила, которыми мы руководствуемся при разделении сети на основе того, кто должен иметь право разговаривать с кем и наоборот.

Решения консула

Решение Consul общей проблемы сегментации сети в распределенных системах заключается в реализации сервисных графиков и взаимного TLS.

Применение политик уровня обслуживания для определения модели трафика и сегментации с помощью Consul

Consul решает проблему сегментации сети, централизованно управляя определением того, кто с кем может разговаривать. У Consul есть специальная функция для этого под названием Consul Connect.

 

Consul Connect регистрирует эти политики межсервисного взаимодействия, которые мы желаем зарегистрировать, и реализует его в рамках графика обслуживания. Таким образом, политика может сказать, что служба A может разговаривать со службой B, но B не может разговаривать с C, например.

Большее преимущество этого заключается в том, что он не ограничен IP-адресом. Скорее это уровень обслуживания. Это делает его масштабируемым. Эта политика будет применяться ко всем экземплярам службы, и не будет никакого жесткого правила брандмауэра, специфичного для IP-адреса службы. Это делает нас независимыми от масштаба нашей дистрибьюторской сети.

Consul Connect также обрабатывает идентификационные данные службы, используя популярный протокол TLS. Он распространяет сертификат TLS, связанный со службой.

Эти сертификаты помогают другим службам надежно идентифицировать друг друга. TLS также помогает обеспечить безопасную связь между службами. Это обеспечивает надежную сетевую реализацию.

Consul применяет TLS с помощью прокси на основе агента, подключенного к каждому экземпляру службы. Этот прокси действует как коляска. Использование прокси-сервера в этом случае не позволяет нам вносить какие-либо изменения в код исходного сервиса.

Это позволяет получить преимущество более высокого уровня применения шифрования для данных в состоянии покоя и данных в процессе передачи. Кроме того, он будет способствовать соблюдению требований законодательства о конфиденциальности и идентификации пользователей.

Базовая архитектура Consul

Consul - это распределенная и высокодоступная система.

Consul поставляется в виде одной двоичной загрузки для всех популярных платформ. Исполняемый файл может работать как клиент, так и сервер.

Каждый узел, предоставляющий услуги Консула, запускает агента Консула. Каждый из этих агентов разговаривает с одним или несколькими серверами Консула.

Агент Консула отвечает за проверку работоспособности служб на узле, как и за проверку работоспособности самого узла. Он не несет ответственности за обнаружение службы или поддержание данных ключа/значения.

Серверы Консула - это место, где хранятся и реплицируются данные.

Consul может работать с одним сервером, но HashiCorp рекомендует запускать набор из 3-5 серверов, чтобы избежать сбоев. Поскольку все данные хранятся на стороне сервера Consul. С одним сервером, сбой может привести к потере данных.

В кластере с несколькими серверами они выбирают лидера между собой. HashiCorp также рекомендует иметь кластер серверов для каждого центра обработки данных.

Во время процесса обнаружения любая служба в поисках других служб может запросить серверы консула или даже агентов консула. Агенты консула автоматически пересылают запросы на серверы консула.

Агент Консула сидит на узле и общается с другими агентами в сети, синхронизируя всю информацию об уровне обслуживания

Если запрос является перекрестным центром обработки данных, то запросы пересылаются сервером Consul на удаленные серверы Consul. Результаты с удаленных серверов Consul возвращаются на исходный сервер Consul.

Начало работы с Consul

Этот раздел посвящен пристальному рассмотрению Consul как инструмента, имеющего некоторый практический опыт.

Скачивание и Установка

Как обсуждалось выше, Consul поставляется в виде одного двоичного файла, загруженного с веб-сайта HashiCorps или из раздела релизов Consul на GitHub.

Один двоичный файл может работать как сервер Консула или даже как агент клиента Консула.

Вы можете скачать Consul отсюда — Страница загрузки Consul.

Различные варианты загрузки Consul на разных операционных системах

Мы скачаем Consul в командной строке по ссылке со страницы загрузки

Распакуйте загруженный zip-файл.

Добавьте его в PATH.

Использование Consul

Как только вы распакуете сжатый файл и поместите двоичный файл под свой путь, вы можете запустить его следующим образом.

Это позволит запустить агента в режиме разработки.

Участники Consul

Пока выполняется приведенная выше команда, вы можете проверить наличие всех участников в Сети Consul.

Учитывая, что у нас работает только один узел, он по умолчанию рассматривается как сервер. Вы можете назначить агента в качестве сервера, указав сервер в качестве параметра командной строки или сервер в качестве параметра конфигурации в конфигурации Consul.

Выходные данные приведенной выше команды основаны на протоколе сплетен и в конечном итоге согласованы.

Consul HTTP API

Для строго согласованного представления агентурной сети Консула мы можем использовать HTTP API, предоставленный консулом из коробки.

Интерфейс DNS Consul

Consul также предоставляет DNS-интерфейс для запросов узлов. По умолчанию он обслуживает DNS на порту 8600. Этот порт настраивается.

Регистрация сервиса на Consul может быть достигнута либо путем написания определения Сервиса, либо путем отправки запроса через соответствующий HTTP API.

Определение Службы Consul

Определение сервиса - это один из популярных способов регистрации сервиса. Давайте рассмотрим один из таких примеров определения сервиса.

Для размещения наших определений служб мы добавим каталог конфигурации, условно именуемый consul.d — ‘.d’ означает, что в этом каталоге имеется набор конфигурационных файлов, а не один конфиг под именем consul.

Напишите определение сервиса для фиктивного веб-приложения Django, работающего на порту 80 на локальном хосте.

Чтобы наш агент-консул знал об этом определении службы, мы можем предоставить ему каталог конфигурации.

Соответствующая информация в журнале здесь - это инструкции синхронизации, относящиеся к службе “web”. Агент Consul принял нашу конфигурацию и синхронизировал ее по всем узлам. В данном случае один узел.

Запрос службы DNS Consul

Мы можем запросить службу с помощью DNS, как это было сделано с узлом. Вот так:

Мы также можем запросить DNS для служебных записей, которые дают нам больше информации о специфике службы, такой как порт и узел.

Вы также можете использовать TAG, предоставленный нами в определении сервиса, для запроса определенного тега:

Каталог услуг Consul через HTTP API

Сервис также может быть запрошен с помощью HTTP API:

Мы можем фильтровать сервисы на основе проверок работоспособности по HTTP API:

Обновление Службы Определения Consul

Если вы хотите обновить определение службы на работающем агенте Consul, это очень просто.

Есть три способа достичь этого. Вы можете отправить сигнал SIGHUP процессу, перезагрузить Consul, который внутренне отправляет SIGHUP на узел, или вы можете вызвать HTTP API, посвященный обновлениям определений служб, которые будут внутренне перезагружать конфигурацию агента.

Отправляем SIGHUP на номер 21289

Или Перезагружаем Consul

Конфигурация перезагрузки срабатывает

Вы должны увидеть это в своем журнале Consul.

Веб-интерфейс Consul.

Consul предоставляет красивый веб-пользовательский интерфейс из коробки. Вы можете получить доступ к нему через порт 8500.

В этом случае http://localhost:8500. Давайте посмотрим на некоторые экраны.

Домашняя страница для служб пользовательского интерфейса Consul со всей соответствующей информацией, связанной с агентом Consul и проверкой веб-службы.

Изучение определенных служб в веб-интерфейсе Consul

Переходя к более подробной информации о данной службе, мы получаем панель мониторинга службы со всеми узлами и их работоспособностью для этой службы.

Изучение информации на уровне узлов для каждой службы в веб-интерфейсе Consul

На каждом отдельном узле мы можем посмотреть проверки работоспособности, службы и сеансы.

Изучение информации о проверке работоспособности конкретного узла, информации об услугах и сеансах в веб-интерфейсе Consul.

В целом, Consul Web UI действительно впечатляет и является отличным компаньоном для инструментов командной строки, которые предоставляет Consul.

Чем Consul отличается от Zookeeper, doozerd и etcd?

Consul имеет первоклассную поддержку для обнаружения услуг, проверки работоспособности, хранения ключевых значений, мульти-центров обработки данных.

Zookeeper, doozerd и etcd в основном основаны на механизме хранения ключей и значений. Чтобы достичь чего-то сверх такого ключевого значения, магазину нужны дополнительные инструменты, библиотеки и пользовательские разработки вокруг них.

Все эти инструменты, включая Consul, используют серверные узлы, которые требуют кворума узлов для работы и строго согласованы.

Более или менее, все они имеют сходную семантику для управления хранилищем ключей/значений.

Эта семантика привлекательна для построения систем обнаружения служб. Consul имеет готовую поддержку для обнаружения служб, которой нет в других системах.

Система обнаружения служб также требует способа выполнения проверок работоспособности. Так же важно проверить работоспособность сервиса, прежде чем позволить другим обнаружить его. Некоторые системы используют биения сердца с периодическими обновлениями и TTL. Работа по этим проверкам здоровья растет с масштабом и требует фиксированной инфра-информации. Окно обнаружения сбоев имеет длину не менее длинны TTL.

В отличие от Zookeeper, у Consul есть агенты-клиенты, сидящие на каждом узле кластера, разговаривающие друг с другом в пуле сплетен. Это позволяет клиентам быть тонкими, дает лучшую возможность проверки работоспособности, снижает сложность на стороне клиента и решает проблемы отладки.

Кроме того, Consul предоставляет встроенную поддержку интерфейсов HTTP или DNS для выполнения общесистемных, узловых или сервисных операций. Другие системы нуждаются в тех, которые разрабатываются вокруг открытых примитивов.

Веб-сайт Кконсула дает хороший комментарий о сравнении между Consul и другими инструментами.

Инструменты С Открытым Исходным Кодом для HashiCorp Consul

HashiCorp и сообщество построили несколько инструментов вокруг Консула

Эти инструменты консула создаются и управляются преданными инженерами HashiCorp:

Consul Template (3.3k stars) — стандартный рендеринг шаблона и уведомления с консулом. Рендеринг шаблонов, уведомитель и супервизор для данных @hashicorp Consul и Vault. Он обеспечивает удобный способ заполнения значений из Consul в файловую систему с помощью демона consul-template.

Envconsul (1.2k stars) — считывает и устанавливает переменные среды для процессов из Consul. Envconsul предоставляет удобный способ запуска подпроцесса с переменными окружения, заполненными из HashiCorp Consul и Vault.

Consul Replicate (360) — Демон Consul cross-DC KV репликации. Этот проект предоставляет удобный способ репликации значений из одного центра обработки данных Consul в другой с помощью демона consul-replicate.

Consul Migrate — средство переноса данных для обработки обновления консул в 0.5.1+.

Сообщество Consul также создало несколько инструментов для помощи в регистрации сервисов и управлении конфигурацией сервисов, я хотел бы упомянуть некоторые из популярных и хорошо поддерживаемых -

Confd (5.9 k stars) — управление локальными конфигурационными файлами приложений с помощью шаблонов и данных из etcd или consul.

Fabio (5.4 k stars) — Fabio - это быстрый, современный маршрутизатор HTTP (S) и TCP с нулевой конфигурацией балансировки для развертывания приложений, управляемых Консулом. Зарегистрируйте свои службы в consul, проведите проверку работоспособности, и Fabio начнет направлять на них трафик. Никакой конфигурации не требуется.

Registrator (3,9 к stars) — Мост реестра служб для Docker с подключаемыми адаптерами. Регистратор автоматически регистрирует и отменяет регистрацию служб для любого контейнера Docker, проверяя контейнеры по мере их поступления в сеть.

Hashi-UI (871 stars) — современный пользовательский интерфейс для HashiCorp Consul & Nomad.

Git2consul (594 звезды) — отражает содержимое репозитория git в Consul KVs. git2consul берет один или несколько репозиториев git и отражает их в Consul KVs. Цель состоит в том, чтобы организации любого размера использовали git в качестве резервного хранилища, контрольного журнала и механизма контроля доступа для изменений конфигурации, а Consul-в качестве механизма доставки.

Spring-cloud-consul (503 stars) — этот проект обеспечивает интеграцию Consul для приложений Spring Boot посредством автоконфигурации и привязки к среде Spring и другим идиомам модели программирования Spring. С помощью нескольких простых аннотаций вы можете быстро включить и настроить общие шаблоны внутри вашего приложения и построить большие распределенные системы с компонентами на основе Consul.

Crypt (453 stars) — храните и извлекайте зашифрованные конфигурации из etcd или consul.

Mesos-Consul (344 stars) — Mesos to Consul bridge для открытия сервиса. Mesos-Consul автоматически регистрирует / отменяет регистрацию служб, запускаемых как задачи Mesos.

Consul-cli (228 stars) — Интерфейс командной строки для Consul HTTP API.

Вывод

Распределенные системы не так просто построить и настроить. Поддержание их в рабочем состоянии - это совсем другая работа. HashiCorp Consul облегчает жизнь инженерам, сталкивающимся с такими проблемами.

По мере того, как мы изучали различные аспекты Consul, мы узнали, насколько простым для нас станет разработка и развертывание приложения с распределенной архитектурой или архитектурой микросервисов.

Простота использования, отличная документация, надежный готовый к производству код и поддержка сообщества позволяют довольно легко адаптировать и внедрить HashiCorp Consul в наш технологический стек.

Мы надеемся, что это была познавательное изучение Consul. Наше путешествие еще не закончилось, это была только первая половина. Мы снова встретимся с вами во второй части этой статьи, которая проведет нас через практические примеры, близкие к реальным приложениям.

Дайте нам знать, что вы хотели бы услышать от нас больше или если у вас есть какие-либо вопросы по этой теме, мы будем более чем рады ответить на них.

Ссылки

HashiCorp Consul и его РЕПО на GitHub

HashiCorp Consul Guides and Code

Микросервисы, как объяснил Мартин Фаулер и др.

Статьи в блоге HashiCorp о компании Consult

*******************************************************************

Этот пост был первоначально опубликован в блоге Velocio.

Velotio Technologies - это аутсорсинговый партнер по разработке программных продуктов для технологических стартапов и предприятий. Мы специализируемся на разработке корпоративных продуктов B2B и SaaS с акцентом на искусственный интеллект и машинное обучение, DevOps и разработку тестов.

Хотите узнать о нас побольше? Мы хотели бы связаться с вами на нашем веб-сайте, LinkedIn или Twitter. 

![](https://habrastorage.org/webt/ft/tv/2u/fttv2utldiku-kqshw1alwm7qwg.png)

![](https://habrastorage.org/webt/9g/mi/zz/9gmizzm2vgackmfe3fkupxq2thy.png)

![](https://habrastorage.org/webt/th/s8/kg/ths8kgysqqthqiq5i8wd8bhvbug.png)

![](https://habrastorage.org/webt/d3/tp/b1/d3tpb1cnifenhuup2e376hmdtke.png)

![](https://habrastorage.org/webt/72/tq/cj/72tqcj5gw6bxf14od0aqkasn2ky.png)

![](https://habrastorage.org/webt/hp/tx/r1/hptxr1vcepjax5pop9h4oijun5m.png)

![](https://habrastorage.org/webt/7s/in/hv/7sinhvboqheb7oibcf3sn_lgy6w.png)

![](https://habrastorage.org/webt/yy/lf/c9/yylfc94cawk5t9c1fmbeqhv0ps0.png)

![](https://habrastorage.org/webt/gl/hz/1x/glhz1xpwm7wpnsesc7wsqhqibhk.png)

![](https://habrastorage.org/webt/dr/ap/1z/drap1zxeceqnwted9kjvghoqvbu.png)

![](https://habrastorage.org/webt/if/zg/0u/ifzg0u53cfwybg-pc2o8eilxfxy.png)

![](https://habrastorage.org/webt/jj/ir/yq/jjiryq-l8bx4fq3khh9gszj0kn0.png)



![](https://habrastorage.org/webt/k8/kk/yq/k8kkyqqaya4aztvwed4sxmfmol8.png)

![](https://habrastorage.org/webt/28/t5/1b/28t51bpkwuf_4nkrq6i-duww73s.png)

![](https://habrastorage.org/webt/i_/go/a_/i_goa_fpbr5g_o2iqmeq85goe4e.png)

![](https://habrastorage.org/webt/r4/75/c2/r475c21szlngnl3hysbfmtzy-_i.png)

![](https://habrastorage.org/webt/er/lu/7b/erlu7buheypao98dg9nae-szrlu.png)

![](https://habrastorage.org/webt/sf/fp/9g/sffp9gc0_2jkpwirztap5wjnrm4.png)

![](https://habrastorage.org/webt/zq/n1/_h/zqn1_hhmipx_wy6zy3mn8hhmcbi.png)

![](https://habrastorage.org/webt/il/mr/wn/ilmrwng8ndsniy2ghkq44fphoza.png)

![](https://habrastorage.org/webt/7f/4u/j5/7f4uj5igx5ds4ci31dvygyjmswq.png)

![](https://habrastorage.org/webt/7f/4u/j5/7f4uj5igx5ds4ci31dvygyjmswq.png)

![](https://habrastorage.org/webt/u7/o_/w7/u7o_w79kb26rqxpondnd0rc_l9g.png)

![](https://habrastorage.org/webt/wh/vb/za/whvbza8dkvxyo9jytwwfklylbam.png)

![](https://habrastorage.org/webt/qi/pj/qe/qipjqetv710f5hlnsghvmodycis.png)

![](https://habrastorage.org/webt/gp/u7/km/gpu7kmph2hcpnr1mqhx2-duj2by.png)

![](https://habrastorage.org/webt/ct/q5/j1/ctq5j1dtpss-bt0xqsg_u_ps8-0.png)

![](https://habrastorage.org/webt/6o/8w/dp/6o8wdplmguyscheyzmezf8zqqhu.png)

![](https://habrastorage.org/webt/js/ge/hb/jsgehbnlautw-bqr9sw7jr6fwwq.png)

![](https://habrastorage.org/webt/bs/yv/pg/bsyvpg67auykppnptt_emg2nola.png)
