Представляем вашему вниманию часто задаваемые вопросы на них от команды Victriametrics.

Вопросы будут отмечены жирным шрифтом.

**Вопрос по интеграции телеграф -> ВМ. Есть ли возможность не проставлять префикс `{measurement}{separator}`? Поскольку телеграф не поддерживает пустую строку в качестве measurement, метрики в ВМ получаются некрасивые**

Пока есть возможность оставлять только {measurement} в качестве имени метрики, если указать флаг -influxSkipSingleField при запуске вм и если в influx line только один field. Запустите victoriametrics с флагом -help, чтобы почитать больше инфы про этот флаг. Если нужно другое поведение (например, оставлять только имя филда без {measurement}{separator}), то создайте feature request на https://github.com/VictoriaMetrics/VictoriaMetrics/issues , чтобы эта задача не забылась

**Сейчас нету возможности использовать relabeling фичу из последней версии, используя helm чарт?**

По идее, она должна работать через extraArgs в хельм-чарте. 

**Подскажите пожалуйста, а есть возможно ли как то сделать external_labels у vmalert-а из коробки? по сути добавить на каждый recording и alerting рул дополнительные лейблы**
Глобального правила нет - только в rule описывать. Подразумевалось что такое будет делаться на стороне собирающей стороны(vmagent)

**А в планах нет создания для него crd для слежения за `kind: serviceMonitor`? было бы полезно**

Уже есть поддержка crd. Через 3 недели возможно будет.

**на графике 10RPS в http приложении, но под капотом оно генерит много запросов к VM, если смотреть rate(vm_http_requests_all_total{1m} ~ 2.2k**.

![](https://habrastorage.org/webt/qk/y-/zw/qky-zw1tfznbez1zjzcexl9wmci.jpeg)

![](https://habrastorage.org/webt/0z/0o/of/0z0oofcbwm6jqslyrs9fkzkj3ss.jpeg)

![](https://habrastorage.org/webt/bp/nl/qy/bpnlqy_mx61wl3_6ufxrib1szjo.jpeg)

**Как видно какое-то время при постоянной нагрузку, латенси было более-менее стабильное, но затем все стало плохо и тест завершился из-за большого количества сетевых ошибок (в тесте есть отсечка - завершаться при определенном пороге).**
**В логам VM ошибок нет, error метрики по нулям. В http приложении во время когда обваливает тест, при попытке подключиться к VM вываливаются ошибки:** 
**"Post "http://127.0.0.1:8428/api/v1/query": read tcp 127.0.0.1:56186->127.0.0.1:8428: read: connection reset by peer"**
**VM запущена с флагами "--storageDataPath=/storage --httpListenAddr=:8428 --search.maxPointsPerTimeseries=40000"**

**Такое ощущение что VM работает, но в какой-то момент наедается и начинает отказывать в выполнении запросов.**

**Интуитивно добавил еще параметров: - "--memory.allowedPercent=10 --search.maxQueueDuration=20s --search.maxConcurrentRequests=4", т.е. уменьшил объем доступной памяти, уменьшил канкаренси для селектов и разрешил запросам дольше находиться в очереди на выполнение.**

**Последующие 2 теста завершились успешно, хотя второй был на грани и когда я увидел тормоза, то думал что он вот-вот обвалится, но нет - рассосалось и продолжило работу**

Попробуйте настроить мониторинг вм и посмотреть, какие графики на официальном дашборде начинают "выбиваться" во время теста. См. https://victoriametrics.github.io/#monitoring .

Подозреваю, что вм упирается в нехватку cpu при повышении входящего rps.  Это приводит к увеличению задержек в очереди ожидания -search.maxQueueDuration. Если входящий запрос проводит в этой очереди больше времени, чем указано в флаге, то вм возвращает ответ "все плохо", что прерывает нагрузочное тестирование.

**Расскажите кратко о основных частях victoriametrics?**

Victoriametrics она чуть более distributed system чем прометей, поэтому  функционал прометея разделили на три сущности - scrapper (vmagent), rule and alerts evaluation (vmalert), tsdb (victoriametrics ) - по причине что так логичней правильней оно скейлится и работает с нагрузкой. Тут я описываю сетап только со стороны прометей стека потому что ВМ может не только его и хорошо справляется

**Постараюсь максимально детально описать.**

**"Можете описать ваш случай - какие данные приходят в вм, с какой периодичностью, как часто у них меняются лейблы, как часто эти данные обнуляются и/или перестают передаваться?"**
**Инкременты. Сейчас это показы баннеров и клики.**
**Скрейп раз в 1 мин - получается 17к временных рядов при ttl=300s в statsd_exporter. Всего в хранилище прома 150к рядов.**
**Очень разнородные данные. Некоторые комбинации меток поступают без остановки неделями. Некоторые постоянно моргают с частотой десятки минут или часов.**
**Но это только начало экспериментов. Скоро кол-во рядов возрастет в несколько раз или даже на порядки за счет других типов событий.**
**Если отказаться от ttl, то statsd_exporter умрет от кол-ва рядов по памяти и цпу, дико вырастет длительность скрейпа (вместо 1 сек будет занимать минуту).**

**"После этого опишите, что вы хотите получить в ответ от вм? Это поможет понять, можно ли решить задачу с помощью вм, и определиться со способом решения."**
**Нужно иметь точную сумму и частоту всех событий. В любых срезах меток. Даже если ряды моргают.**

**Вот пример парочки уникальных рядов**

![](https://habrastorage.org/webt/fv/k6/42/fvk642bzyg53quo2srp5kdtwkvo.jpeg)

Спасибо. Теперь понятно. Т.е. у вас есть много счетчиков, которые могут исчезать, если в течение 300 секунд их значения не увеличились.
Есть следующие варианты решения этой проблемы:

- использовать подзапрос вроде increase((m default 0)[d]). Он вставляет нули вместо пустых значений, поэтому increase должен правильно считать результат, когда значение исчезло, а затем появилось точно такое же. Если не добавлять default 0, то increase вернет 0, иначе - правильно учтет второе значение. Недостаток этого способа - подзапрос может работать медленнее и требовать больше памяти по сравнению с обычным increase(m[d]).
- использовать стандартный statsd вместо statsd_exporter. Statsd вроде по умолчанию сбрасывает все счетчики в ноль после отправки данных на бэкенд (например, на вм). Поэтому в вм можно будет всегда подсчитать точное количество событий за произвольный промежуток времени с помощью sum_over_time(m[d]). Вот тут доки про подключение statsd к вм - https://victoriametrics.github.io/#how-to-send-data-from-graphite-compatible-agents-such-as-statsd . В statsd нужно не забыть включить опцию config.deleteCounters, чтобы он удалял нулевые счетчики.
- написать свой сервис для подсчета счетчиков и регулярной отправки их значений в вм по любому поддерживаемому протоколу - Graphite, Influx, OpenTSDB, CSV и т.д. См. список поддерживаемых протоколов вот тут - https://victoriametrics.github.io/#how-to-import-time-series-data . Обычно такой вариант получается самым оптимальным по производительности и самым гибким в настройке под ваши требования

**Мне не нравится писать адреса в конфигах. но у меня есть дискавери. я хочу указать имя сервиса и сколько в нем есть бэкендов - пусть во все пишется.**

Норм схема. Обычно набор remote_write бэкендов редко меняется. Поэтому надежнее сохранять его в конфиге, который сохраняется в версионированном репозитории вроде git. Это позволяет отслеживать все изменения в конфигах, при необходимости откатывая некорректные и наказывая тех, кто внес эти изменения. Такой подход (infrastructure as a code) также позволяет быстро развернуть окружение "с нуля" (например, после форс-мажора или для деплоя в новом ЦОДе), т.к. все конфиги хранятся в одном репозитории.
Если же управлять конфигами с помощью различных сервис дискавери механизмов, то все вышеуказанные преимущества теряются. Например, будет достаточно сложно отследить, кто, когда и зачем внес изменения в consul, которые привели к поломке прода. Также будет достаточно сложно развернуть идентичное окружение "с нуля", если часть конфигов хранилось где-нибудь в consul, который был безвозвратно утерян.

**А что такое метрика, как бы вы сформулировали?**

Каждый понимает под этим что-то свое.
В моем понимании метрика - это число - результат измерения, полученный в определенный момент времени. У метрики может быть произвольный набор строковых пар "ключ->значение" (ака лейблы), который однозначно идентифицирует временной ряд, образуемый данной метрикой. Этот набор должен содержать минимум одну пару вида __name__="metric_name", где metric_name - это "имя метрики". Типичный экземпляр метрики - это любая незакомментированная строка на странице /metrics любого промовского экспортера. Вроде foo{bar="baz"} 123. Временной ряд - это набор показаний метрики с заданными лейблами в разные моменты времени. Метрики с одинаковым именем, но с разным набором лейблов, создают разные временные ряды.

**sum(irate(container_cpu_usage_seconds_total{name=~".+",instance=~"$server:.*"}) [$interval]) by (name) / sum(machine_cpu_cores{instance=~"$server:.*"})**
**как вот это можно перевести с языка виктории на язык прома?**

Первоначальный запрос, скорее всего, неправильный. Квадртаные скобки должны стоять внутри irate(), а не снаружи. Иначе вм применяет подзапросы, что, скорее всего, не совсем то, что вам нужно. См. https://medium.com/@valyala/prometheus-subqueries-in-victoriametrics-9b1492b720b3 .
Чтобы запрос работал в проме, попробуйте завернуть в scalar() все, что стоит после знака деления.

**Как написать алерт, который сработает в момент, когда для конкретного набора меток пропали метрики. Вот были и пропали.**

**Ну, допустим, есть экспортер, который отдает метрики для N устройств:**

**device_up{id="1"}**
**device_up{id="2"}**
**device_up{id="3"}**
**...**
**device_up{id="N"}**

**каким образом можно отреагировать на то, что один из девайсов был и вот, пропал?**

Можно попробовать через offset. Например, (device_up offset 1h) unless device_up должно вернуть ряды с именем device_up, которые присутствовали час назад, но сейчас отсутствуют.

**Всем привет, подскажите по external.alert.source для vmalert. Я правильно понимаю что я могу передать лейбл из алерта вот в таком формате {{$labeдs.severity|quotesEscape|pathEscape}} для формирования линки или нет?**

все так, только скорей всего надо будет еще external.url в связке использовать чтоб настроить внешний источник - например графана или пром



**Попробовал использовать increase вместо rate в вм - она как раз должна считать отсутствие первой точки как 0. Но кажется я столкнулся с особенностью вики заполнять пустые точки и продлевать предыдущее значение**
**из-за этого increase работает не так как хотелось**
**если предыдущее значение совпадает, то вика считает, что ничего не менялось. можно изменить такое поведение?**

![](https://habrastorage.org/webt/ls/mq/hj/lsmqhjo2j-7uzig5il-uv5pmuy8.jpeg)

это поведение основано на следующих предположениях:
- increase должен применяться только к метрикам типа counter, значения которых начинаются с нуля и затем могут только увеличиваться с течением времени. Исключение - при перезагрузке процесса, с которого собирается метрика, ее значение может обнулиться. Это обнуление учитывается при вычислении increase, как можно видеть на втором графике.
- если в течение какого-то времени значения для метрики типа counter отсутствуют, а потом снова появляются, то считается, что в течение этого времени эти значения продолжали аккумулироваться в источнике данных и не могли быть доставлены в вм по какой-либо причине (например, из-за сетевых проблем или из-за перезагрузки сервисов, стоящих между источником данных и вм). Поэтому на первом графике increase вернул 0 после возобновления значений исходной метрики.

Вообще, модель данных прометеуса (и вм) предполагает, что значения каждой метрики приходят с регулярной периодичностью (scrape_interval). они могут перестать приходить только в двух случаях:
- при временной неработоспособности источника метрики (например, при его перезагрузке или при проблемах с сетью). В этом случае на графике может быть "провал".
- при удалении данной метрики на источнике. В этом случае на графике линия для данной метрики прекращается.

Если у вас какая-то другая модель данных, то есть два выхода:
- подстроить модель данных под вышеописанную
- подтюнить вм с помощью различных command-line флагов, описанных в https://victoriametrics.github.io/#troubleshooting

**Добрый день не подскажите, в инфлуске метрика называется "abc-test", когда я импортирую в викторию с помощью vmctl метрика будет  abc-test_value, но почмеу-то нет значений, я вот думаю не может ли быть проблемы в дефисе?**

Попробуйте `{__name__="abc-test_value"}` или экранировать.

**Почему бы не завести Вику на ceph/s3? Чтобы под ним был бесконечный сторадж аля Thanos но онпремиз? Я понимаю принцип горизонтального масштабирования кластера, что это просто. Но добавление новых машин даёт постоянный оверхед с с репликацией. Иметь что то вроде бесконечного стораджа было бы интересно, тогда кластер можно масштабировать вертикально**

Cторедж на object storage будет работать медленнее стореджа на block storage.

**Мне нужна функция, которая будет трактовать отсутствие данных как 0 или я что-то делаю не так )**

Попробуйте использовать increase вместо rate в вм - она как раз должна считать отсутствие первой точки как 0

**в проме  трактовка отсутствия данных как 0 работает только на двойном интервале скрейпа и при этом криво**

В проме increase пропускает первую точку, а также использует экстраполяцию, в результате которой могут получиться дробные значения при целочисленных изменениях на графике. См. подробности тут - https://github.com/prometheus/prometheus/issues/3746
Я не знаю, как обойти эти особенности прома при вычислении increase

**Просто хочу понять, с чем это может быть связано)**
**до этого использовал prometheus c его стандартным хранилищем метрик**. **сейчас направил на запись в VM**
**дело в том, что если смотреть в старое хранилище, то кол-во скажем 4хх кодов при такой выборке:**

```
topk(10, sum by (filter_name) (increase(nginx_vts_filter_requests_total{direction=~"$status_code", filter_name=~"$domain_name", filter!="/other"}[5m])))
```

**Чуть-ли не в 2, 3 раза больше, чем в VM**

скорее всего, разница получается из-за немного разных алгоритмов для increase в вм и прометеусе. ВМ вычисляет разницу между последней точкой на интервале, указанном в квадратных скобках, и предыдущей точкой, стоящей перед этим интервалом. Прометеус же вместо предыдущей точки перед интервалом берет первую точку в интервале, а потом еще применяет экстраполяцию для вычисления increase на всем интервале, т.к. первая и последняя точки могут находиться не на концах интервала. В итоге промовский increase обычно возвращает совсем не то, что ожидают пользователи, в отличие от вм. См. подробности вот тут  - https://github.com/prometheus/prometheus/issues/3746

**я хочу несколько инстансов ВМ чтобы можно было потерять любую ноду и не заморачиваться бэкапом-рестором, ну потеряли, ну ок, вторая (третья, четвертая...) работает и мы ничего не заметили**

это достигается с помощью репликации в кластерной версии - см. https://victoriametrics.github.io/Cluster-VictoriaMetrics.html#replication-and-data-safety

**у меня есть несколько инстансов прома, которые скрейпят одно и то же одинаково (несколько - для избыточности). я хочу добавить ВМ, но у меня есть ряд вопросов**

**1) правильно ли я понимаю, что мне для каждого инстанса прома надо завести свой инстанс ВМ и писать изо всех промов во все ВМ неправильно?**
**2) у меня есть инстансы, которые (так вышло) содержат данные за разные периоды времени (грубо говоря один инстанс за январь, второй - за февраль). можно ли их данные объединить внутри одного (нескольких) инстансов вм? а если пересекутся диапазоны?**
**3) можно ли веб-консолью прома как-то ходить в ВМ (догадываюсь, что можно запроксировать нжинксом пару локейшнов, но это так себе решение на долгую перспективу)? explore графаны не очень нравится, хочу оставить промовский /graph для ad-hoc использования**
**4) зачем мне ВМ, если я могу наставить promxy поверх прометеев?**

1) Наоборот, лучше писать со всех промов в один ВМ. Это позволяет потом делать запросы поверх данных, собранных со всех промов aka global query view . При этом нужно не забыть установить различные лейблы в секции global для каждого прометеуса, чтобы вм могла отличить данные разных прометеусов по этим лейблам. Вот тут подробности - https://victoriametrics.github.io/#prometheus-setup . Также вместо промов можно попробовать использовать vmagent - он умеет собирать данные аналогично прому, используя промовский конфиг. Вот тут подробности - https://victoriametrics.github.io/vmagent.html 
2) Можно перелить исторические данные из промов в вм с помощью vmctl - см. https://github.com/VictoriaMetrics/vmctl . Если данные пересекаются по времени, то можно включить дедупликацию - см. https://victoriametrics.github.io/#deduplication , чтобы убрать дубли. Если этого не сделать, то вм сохранит в базу все данные, в т.ч. и дубли.
3) Пока ничего лучше, чем проксирование нескольких локейшнов с помощью nginx, мы не сделали. В планах - сделать аналог /graph в вм. См. https://github.com/VictoriaMetrics/VictoriaMetrics/issues/4 . Обычно пользователи обходятся grafana explore , поэтому задача не в приоритете.
4) ВМ позволяет централизованно хранить все данные со всех прометеусов и делать по ним запросы без необходимости подключения к прометеусам. promxy же требует, чтобы прометеусы были доступны. Иначе она может вернуть не все данные в ответах на запросы.

**Не знаю уж, правильно это или нет, но я истерил на тему как подменить исходный таргет на человекопонятное название в метке instance даже в метриках up. Так вот, это по прежнему возможно, если добавить labels.instance для каждого отдельного таргета.**
**Мне подходит.**

понял :) Дополнительные лейблы для всех метрик, в т.ч. и для автоматически сгенерированных, можно сделать на уровне relabel_configs в каждом scrape_config.  Этот релейбелинг выполняется во время service discovery, а не во время скрейпинга метрик, поэтому все лейблы, созданные с помощью relabel_configs, добавляются во все метрики во время скрейпинга.

релейбелинг для автоматически сгенерированных метрик не срабатывает только на уровне metric_relabel_configs

**Что есть "стандартный мониторинг" и как замена метки instance может его поломать?**

метка instance обычно меняется на этапе определения scrape targets с помощью секции relabel_configs. В этот момент метрики еще не собираются, поэтому там нет автоматически создаваемых метрик вроде up и всяких scrape_*. Эти метрики создаются непосредственно после каждого сбора метрик с каждого target'а. В этот момент применяются релейбл-правила, указанные в секции metric_relabel_configs, и на этом этапе нельзя поменять лейблы для автоматических созданных метрик

стандартный мониторинг - это мониторинг состояния scrape target'ов. Например, чтобы алерт по запросу up == 0 возвращал ожидаемые значения job и instance, а не переопределенные на этапе сбора метрик, из-за которых может быть сложно определить, какой из target'ов перестал работать.

**А еще появляется вот такой косяк в графане при этом. Видите пустой пункт списка над alertmanager?**

![](https://habrastorage.org/webt/z-/js/hz/z-jshzyvtkiv7hpyesr30hb8bis.jpeg)

скорее всего, на месте пустого пункта есть имя метрики, содержащее "невидимые" символы вроде пробелов и т.п. Это удобно смотреть с помощью инспектирования ответа в chrome dev tools, возвращаемого в графану при составлении списка метрик для автодополнения

**а как лучше с дупликацией тогда быть? можно ли на vmselect использовать -dedup.minScrapeInterval или нужно только promxy использовать?**

Можно натравить vmselect на все vmstorage ноды во всех дц и использовать дедуплицировать данные с помощью -dedup.minScrapeInterval. Преимущество по сравнению с promxy - есть поддержка всех возможностей MetricsQL. Недостатки:
- сниженная скорость, т.к. данные из внешнего дц обычно загружаются медленнее, чем из локального дц
- повышенные расходы на трафик между дц, т.к. vmselect подгружает все данные со всех vmstorage нод, необходимые для выполнения каждого запроса
- сниженная доступность, т.к. если один дц будет недоступен, то vmselect может возвращать неполные результаты

Также можно попробовать query-tee вместо promxy для обеспечения HA поверх независимых кластеров ВМ в нескольких дц. Преимущество - сниженные задержки ответов, т.к. query-tee не ждет результатов со всех кластеров, а возвращает первый полученный результат. См. https://cortexmetrics.io/docs/operations/query-tee/ .

**Ребят всем привет , подскажите пожалуйста, может кто сталкивался с такой задачей:**
**есть по две ноды в каждом ДЦ, на которих подняты vminsert, vmselect и vmstorage**
**по такой схеме:**

**Нужно организовать репликацию данных между двумя ДЦ**
**Сейчас если кверять данные то вижу что они попадают только на ноды в 1 ДЦ, хотя в инсерте прописаны все 4 ноды с обох ДЦ**
**нужно ли прописывать еще и -replicationFactor=4 ?**

![](https://habrastorage.org/webt/zv/ah/bs/zvahbsxw3g8ix2nzuqokqxhlyc0.jpeg)

Лучше поставить vmagent перед двумя независимыми кластерами вм в разных дц, и записывать все данные через этот vmagent. Он будет реплицировать данные в два кластера, если указать их адреса на запись в нескольких аргументах -remoteWrite.url. Если у вас несколько тенантов, то для каждого тенанта нужно запускать по одному vmagent'у. Перед ними можно поставить vmauth для авторизации запросов и роутинга на нужный vmagent.



**графана не выдает ошибки потому что у нее step больше на этом диапазоне, если добавить step=30m виктория тоже ошибки не выдает, теперь не понятно это правильное поведение или нет (я если честно наивно ожидал хоть каких-нибудь точек хоть и сдаунсемплированых вместо отсутствия данных)**

если точки одного ряда находятся далеко друг от друга (более 5 минут) и расстояние между точками не регулярное, то нужно заворачивать имя метрики во что-нибудь вроде rollup, max_over_time или что-то подобное. Вроде rollup(mambu_hh_requests_milliseconds_count) . Если этого не делать, то вм, как и пром, может ничего не вернуть в ответ. Такое поведение также можно попытаться исправить с помощью флага -search.minStalenessInterval - см. подробности вот тут - https://victoriametrics.github.io/#troubleshooting



**Как-то можно использовать разные стораджы для разных метрик или проектов?**

vminsert в кластерной версии равномерно раскидывает метрики для всех тенантов (accountID) по всем vmstorage нодам. Это гарантирует равномерное распределение данных между vmstorage нодами, и, соответственно, равномерную загрузку vmstorage нод при входящих запросах и линейное масштабирование производительности при добавлении новых vmstorage нод в кластер. Поэтому там нет возможности записывать часть метрик в определенные vmstorage ноды. Если бы такая возможность была, то нагрузка на vmstorage ноды была бы неравномерной, и на них попадал бы разный объем данных.

Если вам нужно физически разделять данные из разных проектов по разным vmstorage нодам, то самый простой вариант - запустить несколько независимых кластеров вм и поставить перед ними проксю вроде vmauth, которая будет направлять входящие запросы от определенного проекта на нужный кластер. См. https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/app/vmauth/README.md



**А аналог push gateway уже есть?**

есть два варианта для замены push gateway:
- пушить метрики напрямую в вм или vmagent по одному из поддерживаемых пуш-протоколов - Influx, Graphite, OpenTSDB, json или csv - см. https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-import-time-series-data
- пушить метрики в statsd, который будет периодически скидывать агрегированные значения в вм. См. https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-send-data-from-graphite-compatible-agents-such-as-statsd

Прямой поддержки push gateway протокола в вм пока нет по следующим причинам:
- push gateway - самый ужасный и неудобный инструмент для пуша метрик. Нужно выдать медаль Брайну за умение оттолкнуть пользователей от пуш-модели
- от пользозвателей вм еще не поступали предложения реализовать поддержку push gateway протокола в вм. Наверное, она мало кому нужна благодаря стараниям Брайна :)



**пишу кастомный импортер который будет через API /import вствлять балком метрики с таймстампами в прошлом:**

```
{
type TimeSeries struct {
 sync.Mutex
 Metric     map[string]string `json:"metric"`
 Values     []float64         `json:"values"`
 Timestamps []float64         `json:"timestamps"`
}
```

**вопросы следующие:**
**1) float64 для обоих полей норм?**
**2) timestamps должны быть постоянно возрастающими, или можно любой таймстамп указывать? если "можно" то насколько критично с точки производительности иметь рандомный диапазон между точками?**
**4) прожует ли /import несколько серий с общими тегами и разными точками? если "да" то лучше постараться все точки запихать в одну кастомную метрику (набор тегов) или вразнобой норм?**

1) для Timestamps лучше использовать тип int64. Там должны передаваться unix timestamps в миллисекундах
2) таймстемпы могут идти в произвольном порядке. Просто если они не отсортированы по возрастанию, то может быть небольшое проседание в скорости вставки, которым в большинстве случаев можно пренебречь. Интервал между таймстемпами может быть произвольным. Если он будет рандомным, то это увеличить объем дискового пространства для хранения таймстемпов. Так что если хотите улучшить сжатие данных, то старайтесь, чтобы интервал между таймстемпами был близок к постоянному.
3) каждая строчка, передаваемая в /api/v1/import, содержит точки только для одной серии, т.к. серия однозначно идентифицируется набором лейбов из metric. Точки для разных серий нужно явно передавать на разных строчках. Количество строк, которые можно передать в одном запросе к /api/v1/import, не ограничено - вм принимает их в потоковом режиме. Количество точек и набор лейблов в каждой строчке может быть произвольным. Одна серия может быть разделена на много строчек - для этого нужно передать несколько строчек с одинаковым набором лейблов, но с разными точками



**Неплохо бы составить список рецептов по выявлению зловредов. Например, как бы получать список коротко-живущих серий с лейблами.**

Короткоживущие серии можно попробовать выявлять с помощью функции lag(m[d]). Она возвращает интервал с момента записи последней точки в каждой серии из m на протяжении интервала времени d. Если это время сильно превышает скрейп интервал, то это говорит о том, что в серию перестали приходить новые точки. Можно еще посмотреть на функцию lifetime из MetricsQL - https://github.com/VictoriaMetrics/VictoriaMetrics/wiki/MetricsQL . Также можно попробовать использовать что-то вроде time() - timestamp(m[d]) > threshold вместо lag(m[d]) > threshold



**Я правильно понимаю что replicationFactor=2 фактически replicationFactoMAX = 2 && replicationFactorMIN = 0**

Vminsert пытается всегда сделать replicationFactor копий поступающих данных на разных нодах vmstorage. В некоторых случаях это не получается. Например, если в данный момент доступно менее чем replicationFactor нод vmstorage. В этом случае vminsert запишет меньшее количество копий данных, упомянет про это в логе, а также увеличит счетчик vm_rpc_rows_incompletely_replicated_total. Этот счетчик появился в версии 1.36.2 . В этой же версии улучшена репликация под высокой нагрузкой



**Вот последнее я и предлагаю немного пофиксить отделенной рутиной которая буде что-то у стораджа спрашивать и будет некий коридор когда она считается живой и рабочей.**

vmstorage считается рабочей, если она принимает подключения от vmselect . Если она по какой-то причине тормозит в то время, как другие vmstorage ноды не тормозят, то тут лучше выяснить и устранить эту причину, чем пытаться обойти ее. Если это связано с какой-то багой, то ее нужно пофиксить. Если это связано с неправильной конфигурацией или железом, на котором запущена vmstorage нода, то это тоже нужно пофиксить.



**Кейс: Выпала одна из нод кластера. vmselect все равно будет к ней ходить и отваливаться по таймауту**

по умолчанию vmselect пытается собрать данные со всех vmstorage нод. Если какая-то из нод недоступна, то он не ждет, пока она появится, а возвращает частичный ответ. Можно указать опцию -search.denyPartialResponse - тогда vmselect вместо частичного ответа будет возвращать ошибку в случае недоступности одной из vmstorage нод.

По идее vmselect может ждать до таймаута только в случае, если какая-нибудь vmselect нода доступна, но почему-то тормозит и долго отдает ответ.



**Есть ли  варианты пренести данные из single версии VM в cluster VM?**

Да, есть. Через экспорт данных из single-node версии с последующим импортом в кластерную версию. См. https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-export-time-series и https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-import-time-series-data .
У этого способа есть недостатки - он медленный при переносе большого объема данных, он требует много временного дискового пространства для хранения экспортированных данных, он достаточно сложный. В будущем планируем добавить более быстрый перенос данных между разными типами вм в уилиту vmctl - https://github.com/VictoriaMetrics/vmctl



**а нету параметра, который бы полностью контролировал использование памяти? Хотелось бы быть уверенным, что vmstorage не уйдет за лимиты пода из-за спайков в траффике, потому что потеря данных после oomkill хуже, чем потеря производительности. или это уже из области фантастики?)**

Основной параметр, которолирующий потребление памяти любым компонентом victoriametrics - это -memory.allowedPercent. К сожалению, этот параметр носит пока только рекомендательный характер - он четко ограничивает размеры внутренних кэшей, но не ограничивает объем временной памяти, необходимый для выполнения запросов. В будущем нужно сделать, чтобы -memory.allowedPercent ограничивал и объем временной памяти.

Что касается потребления памяти vmstorage в поде, то оно может приближаться к выставленным лимитам, т.к. k8s включает в использованную память объем недавно прочитанных данных из файлов, отображенных в адресное пространство процесса (aka mmap). vmstorage по умолчанию использует mmap для ускорения обращения к файлам с данными во время запросов. Поэтому, если текущие запросы затрагивают большое количество данных, то объем этих данных будет включен кубером в объем используемой памяти подом vmstorage. Т.е. он может приблизиться к выставленному лимиту и это нормальное поведение. Выставленный лимит не должен быть превышен, т.к. память, отображенная в адресное пространство процесса, в любой момент может быть освобождена операционкой. Если хотите, чтобы кубернетс учитывал только реально используемую память в vmstorage, то передайте ему флаг -fs.disableMmap. Это может немного повысить нагрузку на CPU и увеличить время выполнения тяжелых запросов, затрагивающих большой объем данных.



**подскажите, пожалуйста, должно ли понижаться потребление памяти на vmstorage при снижении числа active timeseries?**

вполне возможно - время жизни данных в кэшах обычно составляет час. Если в течение часа к этим данным не было обращений, то они удаляются из кэша. Поэтому vmstorage может освободить используемую память в течение часа-двух после уменьшения числа активных рядов.



**Подскажите, если в vminsert параметре указывать несколько vmstorage нод, то по какой логике он их обработает?** 
1. **при старте начнет писать в первую ответившую или в первую по очереди?**
2. **при отказе одной из vmstorage переключится на вторую независимо от ее позиции по очередности?**
3. **при восстановлении после отказа vmstorage, которая была первая в списке - вернется писать в нее или продолжит в ту, на которой остановился?**



1. При старте и нормальной работе данные, поступившие в vminsert, равномерно распределяются по всем имеющимся vmstorage нодам согласно консистентного хэширования от имени метрики плюс всех ее лейблов.
2. При недоступности одной из vmstorage нод, vminsert равномерно распределит ее новые данные поверх оставшихся в живых vminsert нод.
3. При возвращении в строй vmstorage ноды, vminsert вернется к п.1, т.е. будет записывать данные во все имеющиеся vmstorage ноды согласно консистентного хэширования.

Важно сохранять порядок vmstorage нод, переданных в аргументе -storageNode для vminsert при реконфигурации кластера. Если порядок будет часто меняться, то это может привести к повышенному потреблению памяти и cpu на vmstorage нодах, т.к. при изменении порядка меняется распределение временных рядов по vmstorage нодам, что может сильно увеличииь количество сохраненных рядов на каждой ноде.



**Добрый день, такой вопрос - при загрузке бекапа в google bucket есть возможность как-то сжимать бекап? И я правильно понимаю, что при использовании смарт-бекапа, каждая папка в бакете: latest, отдельный день весят как сама база?**

Данные вм и так сжаты, поэтому нет большого смысла пытаться сжать их еще раз при заливке в клауд сторедж.
По поводу размеров каждого бэкапа в клауд сторедже - он равен полному размеру бэкапа, даже если делать инкрементальный бэкап, как уже сказал Артем. При инкрементальном бэкапе vmbackup создает server-side копии для уже существующих файлов из предыдущего бэкапа. Такие файлы обычно создаются моментально, т.к. копирование данных на стороне клауд стореджа не происходит - там копируются только метаданные, т.е. создается новое имя файла, который указывает на старое содержимое. Оплата за такие копии может сниматься как индивидуально за каждую копию, так и только за одну копию. Это зависит от используемого клауд стореджа. Логично, чтобы оплачивалась только одна копия.





**Привет! Стокнулся с некоторой, как мне кажется, странностью. Делаю запрос в VM:**

```
sum(rate(container_cpu_usage_seconds_total{namespace=~"my-namespace", pod=~"my-container"})) by (pod)
```

**Получаю ответ, что не хватает памяти:**

```
error when executing query="sum(rate(container_cpu_usage_seconds_total{namespace=~\"my-namespace\", pod=~\"my-container\"}[10m])) by (pod)" on the time range (start=1588040025000, end=1588061625000, step=15000): cannot execute query: not enough memory for processing 69168000 data points across 4 time series with 1441 points in each time series; possible solutions are: reducing the number of matching time series; switching to node with more RAM; increasing -memory.allowedPercent; increasing `step query arg (15s)
```

**Запрос за 6 часов, шаг 15 секунд, 1441 точка на серию. Всего 4 временные серии. Откуда 69168000 точек для расчёта?**



ВМ оценивает количество необходимой памяти перед выполнением запроса. ВМ использует следующую формулу при оценке количества результирующих рядов - cpu_count * 1000, если в запросе есть агрегация с группировкой по каким-нибудь лейблам вроде sum(...) by (pod), т.к. в результате может получиться намного большее количество рядов при большом количестве значений pod. Число 69168000 получилось путем умножения 1441 (количество точек на каждый ряд, которое нужно вернуть пользователю) на оцененное количество рядов, т.е. на cpu_count * 1000. У вас 69168000 / (1000 * 1441) = 48 процессорных ядер на компе, где работает вм. Сообщение об ошибке немного сбивает с толку числом 4. Там должно стоят cpu_count * 1000 = 48000 в вашем случае. Исправлю это в следующей версии.

По поводу, откуда взялись числа 1000 и cpu_count при оценке количества рядов, которые может вернуть вм.

- 1000 взято "с потолка". Если взять слишком маленькое число, то могут возникать ситуации, когда вм недооценит требуемое количество памяти перед выполнением запроса, что приведет к out of memory.  Если взять слишком большое число, то повышается вероятность возврата ошибок, как в данном случае. Думаю, будет правильным добавить флаг, чтобы пользователь сам мог выставлять приемлемое для него значение.

- cpu_count взялось из-за особенностей расчета агрегирующих функций. ВМ запускает расчет параллельно на всех имеющихся ядрах cpu. Поэтому на каждом ядре может набраться до 1000 результирующих рядов, которые потом будут объединены со всех cpu.

Пути решения этой проблемы:
- увеличить объем памяти для вм
- запустить вм с env var GOMAXPROCS=8, чтобы ей было доступно меньшее количество ядер проца (в данном случае будет доступно 8 ядер вместо 48), что должно снизить оцениваемый объем памяти перед выполнением запроса в 6 раз.
- увеличить аргумент step в запросе, чтобы уменьшить количество возвращаемых точек на каждый ряд. Сейчас возвращается 1441 точка на ряд для step=15s. Если его увеличить до 30s, то оцениваемый объем памяти снизится в два раза. В графане это делается с помощью настройки resolution при редактировании графика. Поменяйте его с 1/2 на 1/4, чтобы увеличить step в два раза.